{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamPeetz/stable_diffusion/blob/main/latent_space_walks_V5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Latent Space Interpolations with Stable Diffusion\n",
        "\n",
        "The input manifold of the diffusion model is a hypersphere of noise. Words are encoded to locations in the hypersphere which can be translated into images by the model. The intermediate points between two encoded prompts can be calculated and fed into the model to create a smooth transition between two images. This process is called latent space interpolation."
      ],
      "metadata": {
        "id": "qSCnHSvY8mdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Keras CV Library\n",
        "\n",
        "The Keras_CV library contains the stable diffusion model and must be installed seperate from the rest of the Keras package."
      ],
      "metadata": {
        "id": "R3yL2wy49JR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3_FFTlsrigY",
        "outputId": "2bf0bff0-0764-456c-cbc9-0abb0fb616c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/721.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.6/721.6 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow keras_cv --upgrade --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Required Libraries\n",
        "\n",
        "Several support libraries are used in this noteboook.\n",
        "\n",
        "Keras_CV and Keras provide API support for working with nueral networks. <br>\n",
        "Tensorflow and Numpy are used for tensor manipulation.<br>\n",
        "Math provides support for equations used in the code.<br>\n",
        "Matplotlib is used to generate images.<br>\n",
        "TQDM is used to record the progress of looping operations.<br>\n",
        "OS and Shutil are used to navigate directory structures.<br>\n",
        "Google.Colab Drive allows the notebook to communicate with a gmail drive.<br>\n"
      ],
      "metadata": {
        "id": "GAWbXMii8nSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r1iyD-nt5VA",
        "outputId": "84062161-ca30-4989-e1b3-f3b605c39a6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import keras_cv\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import os, shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clear the Keras Backend\n",
        "\n",
        "Clear the Keras backend between succesive model runs to reset as variables stored in the backend may contain information from previous runs."
      ],
      "metadata": {
        "id": "ry9hFfkC8qWw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy6bVBUUS1rZ"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Stable Diffusion Model\n",
        "\n",
        "A stable diffusion model object is defined here for use in multiple areas of the notebook.\n",
        "\n",
        "The dimensions of the image the model produces are selected at this point. The image dimensions must match the noise variable dimensions in the text encoding prompt cell. The image dimensions are required to be a factor of an acceptable input tensor for the model.\n",
        "\n",
        "The image dimensions have a significant impact on the image generated by the model and the resources required to create that image. Image resolution can be increased after the model has run using an ESRGAN and a CPU."
      ],
      "metadata": {
        "id": "cIC7XRye8q_t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH_N-h73M76I",
        "outputId": "81a85d00-908f-4608-e02f-3da12c0309c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n"
          ]
        }
      ],
      "source": [
        "# Enable mixed precision\n",
        "# (only do this if you have a recent NVIDIA GPU)\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# define image dimensions\n",
        "height = 768\n",
        "width = 512\n",
        "\n",
        "# Instantiate the Stable Diffusion model\n",
        "model = keras_cv.models.StableDiffusion(img_height=height, img_width=width, jit_compile=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjfj7bPMKdIP"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "### save_images\n",
        "\n",
        "Saves images created by the model to a single directory location.\n",
        "\n",
        "### glob_save_images\n",
        "\n",
        "Saves images created by the model to a series of directory locations. Google Colab and Drive are known to expereince errors when directories contain too many files. Globbed directory structures help colab and drive overcome these challenges. The logic structure of the code currently supports runs of up to 1100 total images.\n",
        "\n",
        "### slerp\n",
        "\n",
        "The latent space of the model is a hypersphere. Linear interpolation between two points in the sphere does not create a smooth transition between two images. A spherical linear interpolation, or slerp, generates an arc between two points in space. It results in smoother transitions between images when used for latent space walks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0jr7M50C0Sl"
      },
      "outputs": [],
      "source": [
        "def save_images(image_library, image_counter):\n",
        "  for idx in tqdm(range(len(image_library))):\n",
        "   plt.figure(figsize=(10,10))\n",
        "   plt.imshow(image_library[idx][0])\n",
        "   plt.axis('off')\n",
        "   filename = '/content/gdrive/My Drive/planegan/sample_output_2/generated_plot_%05d.png' % (image_count+1)\n",
        "   plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "   plt.close()\n",
        "   image_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7Yhz1fNbRCL"
      },
      "outputs": [],
      "source": [
        "def glob_save_images(base_directory, image_library, image_counter):\n",
        "  file_count = len(image_library)\n",
        "  globbed_dir_num = int((file_count/100)+1)\n",
        "  glob_file = 0\n",
        "  for flc in range(0, globbed_dir_num):\n",
        "      os.makedirs(base_directory + \"%05d\" % (flc+1))\n",
        "  for idx in tqdm(range(len(image_library))):\n",
        "    if idx  >= 0 and idx <= 100:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05s.png\" % ((glob_file+1), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 101 and idx <= 200:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+2), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 201 and idx <= 300:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+3),( image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 301 and idx <= 400:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+4), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 401 and idx <= 500:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+5), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 501 and idx <= 600:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+6), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 601 and idx <= 700:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+7), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 701 and idx <= 800:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+8), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 801 and idx <= 900:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+9), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 901 and idx <= 1000:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+10), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1\n",
        "    if idx >= 1001 and idx <= 1100:\n",
        "         plt.figure(figsize=(10,10))\n",
        "         plt.imshow(image_library[idx][0])\n",
        "         plt.axis('off')\n",
        "         filename = base_directory + \"%05d/generated_plot_%05d.png\" % ((glob_file+11), (image_counter+1))\n",
        "         plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "         plt.close()\n",
        "         image_counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9Y-T5Rc4EnO"
      },
      "outputs": [],
      "source": [
        "# function for spherical interpolation pathway\n",
        "def slerp(t, v0, v1, DOT_THRESHOLD=0.9995):\n",
        "\n",
        "    #convert V0 and V1 to numpy arrays\n",
        "    v0 = v0.numpy()\n",
        "    v1 = v1.numpy()\n",
        "\n",
        "    #calculate dot product of vectors\n",
        "    dot = np.sum(v0 * v1 / (np.linalg.norm(v0) * np.linalg.norm(v1)))\n",
        "    #if transformation would not be meaningful, do linear interpolation\n",
        "    if np.abs(dot) > DOT_THRESHOLD:\n",
        "        v2 = (1 - t) * v0 + t * v1\n",
        "    # otherwise, spheical interpolate\n",
        "    else:\n",
        "        theta_0 = np.arccos(dot)\n",
        "        sin_theta_0 = np.sin(theta_0)\n",
        "        theta_t = theta_0 * t\n",
        "        sin_theta_t = np.sin(theta_t)\n",
        "        s0 = np.sin(theta_0 - theta_t) / sin_theta_0\n",
        "        s1 = sin_theta_t / sin_theta_0\n",
        "        v2 = s0 * v0 + s1 * v1\n",
        "\n",
        "        #convert vectors back to tensor object\n",
        "        v2 = tf.convert_to_tensor(v2, float)\n",
        "\n",
        "    #return new vector\n",
        "    return v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAQi13V8KhPZ"
      },
      "source": [
        "## Encode Text Prompts to the Models Latent Space\n",
        "\n",
        "Generates encodings for text prompts and defines other variables used in the model.\n",
        "\n",
        "A seed can be imposed. This allows results to be duplicated between runs.\n",
        "\n",
        "Positive prompts are defined as strings and squeezed into encodings. Model results are improved when prompts have a level of complexity.\n",
        "\n",
        "A negative prompt can be used to further steer the model. A negative prompt guides the model away from certain types of images.\n",
        "\n",
        "The number of interpolation steps correlates to the number of intermediate images produced by the model.\n",
        "\n",
        "The batch size is the number of images produced at each step. This should be set to 1 as the model will produce duplicate images if the batch size is larger than 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VQ22TJF2FLwd"
      },
      "outputs": [],
      "source": [
        "# set noise seed for repeatability\n",
        "seed = 4121990\n",
        "\n",
        "# calculate noise input dimensions based on image dimensions\n",
        "noise = tf.random.normal((768 // 8, 512// 8, 4), seed=seed)\n",
        "\n",
        "# define positive string prompts\n",
        "prompt_1 = \"galaxies in space from a distance, fractal, psytrance, high quality, masterpeice, high definition, highly detailed, elegant, sharp focus, digital painting, scifi, fantasy, center frame\"\n",
        "prompt_2 = \" devouring black holes in space, fractal, psytrance, high quality, masterpeice, high definition, highly detailed, elegant, sharp focus,concept art, digital painting, scifi, fantasy, center frame\"\n",
        "prompt_3 = \"battle between heaven and hell over a planet in space, explosions, fractal, psytrance, high quality, masterpeice, high definition, highly detailed, sharp focus, digital painting, scifi, fantasy\"\n",
        "\n",
        "# define negative string prompts\n",
        "negative = \"extra limbs, bad art, watermark, face, dull, pencils, error, malformed, low detail, jpeg artifacts, cropped, plain background, ugly, low-res, poorly drawn face, out of frame, poorly drawn hands, blurry, bad art, extra hands, bad anatomy, amputee, missing limbs, amputated\"\n",
        "# set number of interpolation steps between points in space\n",
        "interpolation_steps = 256\n",
        "# define model batch size (1 for 1 image at each step, if seed is fixed, will produce duplicates of the same image)\n",
        "batch_size = 1\n",
        "# create number of batches\n",
        "batches = (interpolation_steps) // batch_size\n",
        "\n",
        "# encode prompt to latent space\n",
        "encoding_1 = tf.squeeze(model.encode_text(prompt_1))\n",
        "encoding_2 = tf.squeeze(model.encode_text(prompt_2))\n",
        "encoding_3 = tf.squeeze(model.encode_text(prompt_3))\n",
        "                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpolate Points Between Prompt N and N and Generate Images\n",
        "\n",
        "Generate arcs between two encodings and create images with locations on each arc.\n",
        "\n",
        "A tensor list variable is defined to hold locations along an arc. Those locations are calculated with slep and appended to the tensor list.\n",
        "\n",
        "An images variable is defined and the model is run to generate an image tensor for each point in the tensor list. Those image tensors are appended to the images variable.\n",
        "\n",
        "This cluster of code is repeated for each text encoding the model interpolates between. In this example, 3 encodings forming a circle."
      ],
      "metadata": {
        "id": "Dd__d4qL9vE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# employ slerp\n",
        "# divide points between 0 and 1 in linerspace based on the number of steps you want\n",
        "tensor_list = []\n",
        "for _, t in enumerate(np.linspace(0, 1, interpolation_steps)):\n",
        "    new_latent = slerp(float(t), encoding_1, encoding_2)\n",
        "    tensor_list.append(new_latent)\n",
        "\n",
        "images = []\n",
        "print(range(interpolation_steps))\n",
        "for batch in range(interpolation_steps):\n",
        "    print(batch)\n",
        "    images.append(\n",
        "      model.generate_image(\n",
        "            tensor_list[batch],\n",
        "            negative_prompt=negative,\n",
        "            batch_size=batch_size,\n",
        "            diffusion_noise=noise,\n",
        "                           )\n",
        "                  )"
      ],
      "metadata": {
        "id": "NJc4OF1k87Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tNmwORi8V3Jg"
      },
      "outputs": [],
      "source": [
        "# employ slerp\n",
        "# divide points between 0 and 1 in linerspace based on the number of steps you want\n",
        "tensor_list = []\n",
        "for _, t in enumerate(np.linspace(0, 1, interpolation_steps)):\n",
        "    new_latent = slerp(float(t), encoding_2, encoding_3)\n",
        "    tensor_list.append(new_latent)\n",
        "\n",
        "print(range(interpolation_steps))\n",
        "for batch in range(interpolation_steps):\n",
        "    print(batch)\n",
        "    images.append(\n",
        "      model.generate_image(\n",
        "            tensor_list[batch],\n",
        "            negative_prompt=negative,\n",
        "            batch_size=batch_size,\n",
        "            diffusion_noise=noise,\n",
        "                           )\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "baT5zykRWWCB"
      },
      "outputs": [],
      "source": [
        "# employ slerp\n",
        "# divide points between 0 and 1 in linerspace based on the number of steps you want\n",
        "tensor_list = []\n",
        "for _, t in enumerate(np.linspace(0, 1, interpolation_steps)):\n",
        "    new_latent = slerp(float(t), encoding_3, encoding_1)\n",
        "    tensor_list.append(new_latent)\n",
        "\n",
        "print(range(interpolation_steps))\n",
        "for batch in range(interpolation_steps):\n",
        "    print(batch)\n",
        "    images.append(\n",
        "      model.generate_image(\n",
        "            tensor_list[batch],\n",
        "            negative_prompt=negative,\n",
        "            batch_size=batch_size,\n",
        "            diffusion_noise=noise,\n",
        "                           )\n",
        "                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Generated Images to a Directory\n",
        "\n",
        "The image tensors stored in the images variable are translated to .pngs by matplot lib and exported to a directory"
      ],
      "metadata": {
        "id": "PPWmGxze-Os7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4H8Y4Qq1IqD"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "base_directory = '/content/gdrive/My Drive/planegan/sample_output_4/'\n",
        "glob_save_images(base_directory, images, counter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPmvhc6iwnLG"
      },
      "source": [
        "# Circular Noise Walks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq4PIoMywm4O",
        "outputId": "046fd556-4bd5-4bf5-a778-9b1b3b5d091d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true\n",
            "1356917/1356917 [==============================] - 0s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5\n",
            "492466864/492466864 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# set noise seed for repeatability\n",
        "tf.random.set_seed(12345)\n",
        "set_seed = 500\n",
        "\n",
        "# calculate noise input dimensions based on image dimensions\n",
        "noise = tf.random.normal((768 // 8, 512// 8, 4), seed=set_seed)\n",
        "\n",
        "circular_prompt = \"devouring black holes in space, fractal, psytrance, high quality, masterpeice, high definition, highly detailed, elegant, sharp focus,concept art, digital painting, scifi, fantasy, center frame\"\n",
        "negative = \"extra limbs, bad art, watermark, face, dull, pencils, error, malformed, low detail, jpeg artifacts, cropped, plain background, ugly, low-res, poorly drawn face, out of frame, poorly drawn hands, blurry, bad art, extra hands, bad anatomy, amputee, missing limbs, amputated\"\n",
        "encoding = tf.squeeze(model.encode_text(circular_prompt))\n",
        "walk_steps = 1024\n",
        "batch_size = 1\n",
        "batches = walk_steps // batch_size\n",
        "\n",
        "walk_noise_x = tf.random.normal(noise.shape, dtype=tf.float64, seed=set_seed)\n",
        "walk_noise_y = tf.random.normal(noise.shape, dtype=tf.float64, seed=set_seed)\n",
        "\n",
        "# noise linespace halved for test\n",
        "walk_scale_x = tf.cos(tf.linspace(0, 1, walk_steps) * math.pi)\n",
        "walk_scale_y = tf.sin(tf.linspace(0, 1, walk_steps) * math.pi)\n",
        "noise_x = tf.tensordot(walk_scale_x, walk_noise_x, axes=0)\n",
        "noise_y = tf.tensordot(walk_scale_y, walk_noise_y, axes=0)\n",
        "noise = tf.add(noise_x, noise_y)\n",
        "batched_noise = tf.split(noise, batches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3r7WjY-8B13g"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "for batch in range(batches):\n",
        "    print(batch)\n",
        "    images.append(\n",
        "        model.generate_image(\n",
        "            encoding,\n",
        "            batch_size=batch_size,\n",
        "            negative_prompt=negative,\n",
        "            diffusion_noise=batched_noise[batch],\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3wBG_76tyEzD"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "base_directory = '/content/gdrive/My Drive/planegan/sample_output_3/'\n",
        "glob_save_images(base_directory, images, counter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OheGIGlEKtbv"
      },
      "source": [
        "## Unassign Cloud GPU\n",
        "\n",
        "For google colab, use this section of code to disconnect the GPU after the run has completed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4oqGPWg2s3XB"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyO0SmC1+Bf8ylTWhVGtSgvO",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}