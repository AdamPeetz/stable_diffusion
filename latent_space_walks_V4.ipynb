{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamPeetz/stable_diffusion/blob/main/latent_space_walks_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3_FFTlsrigY",
        "outputId": "bbd7d298-0f1a-4820-beed-f593c24f857e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/721.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.6/721.6 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow keras_cv --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r1iyD-nt5VA",
        "outputId": "24fea0ef-86a7-408b-97f0-bac77c8d59c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import keras_cv\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os, shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from matplotlib import pyplot\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy6bVBUUS1rZ"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH_N-h73M76I",
        "outputId": "f8451696-f488-4cbb-eab2-c72d37809fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n"
          ]
        }
      ],
      "source": [
        "# Enable mixed precision\n",
        "# (only do this if you have a recent NVIDIA GPU)\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# define image dimensions\n",
        "height = 768\n",
        "width = 512\n",
        "\n",
        "# Instantiate the Stable Diffusion model\n",
        "model = keras_cv.models.StableDiffusion(img_height=height, img_width=width, jit_compile=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "jjfj7bPMKdIP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0jr7M50C0Sl"
      },
      "outputs": [],
      "source": [
        "def save_images(image_library, image_count):\n",
        "  for idx in tqdm(range(len(image_library))):\n",
        "   plt.figure(figsize=(10,10))\n",
        "   plt.imshow(image_library[idx][0])\n",
        "   plt.axis('off')\n",
        "   filename = '/content/gdrive/My Drive/planegan/sample_output_2/generated_plot_%05d.png' % (image_count+1)\n",
        "   plt.savefig(filename, transparent=True,bbox_inches=\"tight\",pad_inches=0.0 )\n",
        "   plt.close()\n",
        "   image_count += 1\n",
        "  return image_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9Y-T5Rc4EnO"
      },
      "outputs": [],
      "source": [
        "# function for spherical interpolation pathway\n",
        "def slerp(t, v0, v1, DOT_THRESHOLD=0.9995):\n",
        "\n",
        "    #convert V0 and V1 to numpy arrays\n",
        "    v0 = v0.numpy()\n",
        "    v1 = v1.numpy()\n",
        "\n",
        "    #calculate dot product of vectors\n",
        "    dot = np.sum(v0 * v1 / (np.linalg.norm(v0) * np.linalg.norm(v1)))\n",
        "    #if transformation would not be meaningful, do linear interpolation\n",
        "    if np.abs(dot) > DOT_THRESHOLD:\n",
        "        v2 = (1 - t) * v0 + t * v1\n",
        "    # otherwise, spheical interpolate\n",
        "    else:\n",
        "        theta_0 = np.arccos(dot)\n",
        "        sin_theta_0 = np.sin(theta_0)\n",
        "        theta_t = theta_0 * t\n",
        "        sin_theta_t = np.sin(theta_t)\n",
        "        s0 = np.sin(theta_0 - theta_t) / sin_theta_0\n",
        "        s1 = sin_theta_t / sin_theta_0\n",
        "        v2 = s0 * v0 + s1 * v1\n",
        "\n",
        "        #convert vectors back to tensor object\n",
        "        v2 = tf.convert_to_tensor(v2, float)\n",
        "\n",
        "    #return new vector\n",
        "    return v2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SLERP Latent Space Interpolations Between Two Prompts"
      ],
      "metadata": {
        "id": "BAQi13V8KhPZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VQ22TJF2FLwd"
      },
      "outputs": [],
      "source": [
        "# set noise seed for repeatability\n",
        "seed = 44\n",
        "\n",
        "# calculate noise input dimensions based on image dimensions\n",
        "noise = tf.random.normal((768 // 8, 512// 8, 4), seed=seed)\n",
        "\n",
        "# define positive string prompts\n",
        "prompt_1 = \"galaxies in space from a distance, fractal, psytrance, high quality, masterpeice, high definition, highly detailed, elegant, sharp focus, digital painting, scifi, fantasy, center frame\"\n",
        "prompt_2 = \" devouring black holes in space, fractal, psytrance, high quality, masterpeice, high definition, highly detailed, elegant, sharp focus,concept art, digital painting, scifi, fantasy, center frame\"\n",
        "prompt_3 = \"battle between heaven and hell over a planet in space, explosions, fractal, psytrance, high quality, masterpeice, high definition, highly detailed, sharp focus, digital painting, scifi, fantasy\"\n",
        "#prompt_4 = \"crystal planet from orbit with a sun in the background, fractal, psytrance, high quality, masterpeice, high definition, highly detailed, elegant, sharp focus,concept art, character concepts, digital painting, scifi, fantasy, center frame, anatomically correct\"\n",
        "#prompt_5 = \"crystal jungle, plants made of metal, fractal, psytrance, high quality, masterpeice, high definition, highly detailed, elegant, sharp focus,concept art, character concepts, digital painting, scifi, fantasy, center frame, anatomically correct\"\n",
        "\n",
        "# define negative string prompts\n",
        "negative = \"extra limbs, bad art, watermark, face, dull, pencils, error, malformed, low detail, jpeg artifacts, cropped, plain background, ugly, low-res, poorly drawn face, out of frame, poorly drawn hands, blurry, bad art, extra hands, bad anatomy, amputee, missing limbs, amputated\"\n",
        "# set number of interpolation steps between points in space\n",
        "interpolation_steps = 256\n",
        "# define model batch size (1 for 1 image at each step, if seed is fixed, will produce duplicates of the same image)\n",
        "batch_size = 1\n",
        "# create number of batches\n",
        "batches = (interpolation_steps) // batch_size\n",
        "\n",
        "# encode prompt to latent space\n",
        "encoding_1 = tf.squeeze(model.encode_text(prompt_1))\n",
        "encoding_2 = tf.squeeze(model.encode_text(prompt_2))\n",
        "encoding_3 = tf.squeeze(model.encode_text(prompt_3))\n",
        "#encoding_4 = tf.squeeze(model.encode_text(prompt_4))\n",
        "#encoding_5 = tf.squeeze(model.encode_text(prompt_5))\n",
        "\n",
        "# employ slerp\n",
        "# divide points between 0 and 1 in linerspace based on the number of steps you want\n",
        "tensor_list = []\n",
        "for _, t in enumerate(np.linspace(0, 1, interpolation_steps)):\n",
        "    new_latent = slerp(float(t), encoding_1, encoding_2)\n",
        "    tensor_list.append(new_latent)\n",
        "\n",
        "images = []\n",
        "print(range(interpolation_steps))\n",
        "for batch in range(interpolation_steps):\n",
        "    print(batch)\n",
        "    images.append(\n",
        "      model.generate_image(\n",
        "            tensor_list[batch],\n",
        "            negative_prompt=negative,\n",
        "            batch_size=batch_size,\n",
        "            diffusion_noise=noise,\n",
        "                           )\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1eqDBm7NPX2k",
        "outputId": "fdf6933d-3717-4ee5-dcb8-6666b7eb7a9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [01:41<00:00,  2.51it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counter = 0\n",
        "save_images(images, counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tNmwORi8V3Jg"
      },
      "outputs": [],
      "source": [
        "# employ slerp\n",
        "# divide points between 0 and 1 in linerspace based on the number of steps you want\n",
        "tensor_list = []\n",
        "for _, t in enumerate(np.linspace(0, 1, interpolation_steps)):\n",
        "    new_latent = slerp(float(t), encoding_2, encoding_3)\n",
        "    tensor_list.append(new_latent)\n",
        "\n",
        "images = []\n",
        "print(range(interpolation_steps))\n",
        "for batch in range(interpolation_steps):\n",
        "    print(batch)\n",
        "    images.append(\n",
        "      model.generate_image(\n",
        "            tensor_list[batch],\n",
        "            negative_prompt=negative,\n",
        "            batch_size=batch_size,\n",
        "            diffusion_noise=noise,\n",
        "                           )\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R4ZbTL8hC9Wp",
        "outputId": "0c85a696-4b62-448b-aa6e-30a11c82281c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 256/256 [03:45<00:00,  1.14it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counter = 256\n",
        "save_images(images,counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "baT5zykRWWCB"
      },
      "outputs": [],
      "source": [
        "# employ slerp\n",
        "# divide points between 0 and 1 in linerspace based on the number of steps you want\n",
        "tensor_list = []\n",
        "for _, t in enumerate(np.linspace(0, 1, interpolation_steps)):\n",
        "    new_latent = slerp(float(t), encoding_3, encoding_1)\n",
        "    tensor_list.append(new_latent)\n",
        "\n",
        "images = []\n",
        "print(range(interpolation_steps))\n",
        "for batch in range(interpolation_steps):\n",
        "    print(batch)\n",
        "    images.append(\n",
        "      model.generate_image(\n",
        "            tensor_list[batch],\n",
        "            negative_prompt=negative,\n",
        "            batch_size=batch_size,\n",
        "            diffusion_noise=noise,\n",
        "                           )\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7qcIv6nKDCFB"
      },
      "outputs": [],
      "source": [
        "counter = 512\n",
        "save_images(images, counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GT0FteOCDGz0"
      },
      "outputs": [],
      "source": [
        "# employ slerp\n",
        "# divide points between 0 and 1 in linerspace based on the number of steps you want\n",
        "tensor_list = []\n",
        "for _, t in enumerate(np.linspace(0, 1, interpolation_steps)):\n",
        "    new_latent = slerp(float(t), encoding_4, encoding_5)\n",
        "    tensor_list.append(new_latent)\n",
        "\n",
        "images = []\n",
        "print(range(interpolation_steps))\n",
        "for batch in range(interpolation_steps):\n",
        "    print(batch)\n",
        "    images.append(\n",
        "      model.generate_image(\n",
        "            tensor_list[batch],\n",
        "            negative_prompt=negative,\n",
        "            batch_size=batch_size,\n",
        "            diffusion_noise=noise,\n",
        "                           )\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rRGXGKkDJ8M"
      },
      "outputs": [],
      "source": [
        "counter = 768\n",
        "save_images(images, counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJEi4O2WmOFV"
      },
      "outputs": [],
      "source": [
        "plt.clf()\n",
        "plt.close()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPmvhc6iwnLG"
      },
      "source": [
        "# Circular Noise Walks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq4PIoMywm4O"
      },
      "outputs": [],
      "source": [
        "# set noise seed for repeatability\n",
        "seed = 44\n",
        "\n",
        "# calculate noise input dimensions based on image dimensions\n",
        "noise = tf.random.normal((768 // 8, 512// 8, 4), seed=seed)\n",
        "\n",
        "circular_prompt = \"galaxies in space from a distance, fractal, psytrance, high quality, masterpeice, high definition, highly detailed, elegant, sharp focus, digital painting, scifi, fantasy, center frame\"\n",
        "negative = \"extra limbs, bad art, watermark, face, dull, pencils, error, malformed, low detail, jpeg artifacts, cropped, plain background, ugly, low-res, poorly drawn face, out of frame, poorly drawn hands, blurry, bad art, extra hands, bad anatomy, amputee, missing limbs, amputated\"\n",
        "encoding = tf.squeeze(model.encode_text(circular_prompt))\n",
        "walk_steps = 1024\n",
        "batch_size = 1\n",
        "batches = walk_steps // batch_size\n",
        "\n",
        "walk_noise_x = tf.random.normal(noise.shape, dtype=tf.float64)\n",
        "walk_noise_y = tf.random.normal(noise.shape, dtype=tf.float64)\n",
        "\n",
        "walk_scale_x = tf.cos(tf.linspace(0, 2, walk_steps) * math.pi)\n",
        "walk_scale_y = tf.sin(tf.linspace(0, 2, walk_steps) * math.pi)\n",
        "noise_x = tf.tensordot(walk_scale_x, walk_noise_x, axes=0)\n",
        "noise_y = tf.tensordot(walk_scale_y, walk_noise_y, axes=0)\n",
        "noise = tf.add(noise_x, noise_y)\n",
        "batched_noise = tf.split(noise, batches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3r7WjY-8B13g"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "for batch in range(batches):\n",
        "    print(batch)\n",
        "    images.append(\n",
        "        model.generate_image(\n",
        "            encoding,\n",
        "            batch_size=batch_size,\n",
        "            negative_prompt=negative,\n",
        "            diffusion_noise=batched_noise[batch],\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wBG_76tyEzD"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "save_images(images, counter)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unassign Cloud GPU"
      ],
      "metadata": {
        "id": "OheGIGlEKtbv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oqGPWg2s3XB"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPUqJm/zgz/9JLrl1h0mqFW",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}